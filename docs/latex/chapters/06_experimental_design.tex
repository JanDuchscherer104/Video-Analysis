

% 5. Training and Evaluation Paradigm
\chapter{Training and Evaluation Paradigm}
\label{ch:experimental_design}

\section{Training Environment and Hyperparameter Configuration}
\label{sec:exp_training_env}
Specification of the computational setup (PyTorch Lightning, WandB for experiment tracking and logging) and critical hyperparameters. Configuration management via Pydantic. List of hyperparameters (e.g., batch size, learning rate, number of epochs, etc.) and their respective values. Discussion of the rationale behind the selected configurations.

\section{Optimization Strategy and Learning Objective}
\label{sec:exp_optimization}
    \subsection{Loss Function Formulation}
    Detailed specification of the loss function(s) employed for MTR training, including components for trajectory regression and mode probability classification. Discussion of how this objective function guides the model to learn multimodal distributions (e.g., relationship to Brier-FDE if incorporated).
    \subsection{Optimizer Selection}
    e.g., Adam optimizer with specified learning rate and scheduling.

\section{Evaluation Metrics}
\label{sec:exp_metrics}
Mathematical definitions and rationale for the selection of:
\begin{itemize}
    \item Average Displacement Error (ADE): $\text{ADE}=\mathbb{E}_{t}[||\hat{y}_{t}-y_{t}||_{2}]$
    \item Final Displacement Error (FDE): $\text{FDE}=||\hat{y}_{T}-y_{T}||_{2}$
    \item Miss Rate (MR): $\text{MR}=\mathbb{E}_{k}[\mathbb{I}\{||\hat{y}_{T}^{(k)}-y_{T}||_{2}>d_{\text{thresh}}\}]$
    \item Brier Final Displacement Error (BrierFDE): $\text{BrierFDE}=\mathbb{E}_{k}[p_{k}\cdot||\hat{y}_{T}^{(k)}-y_{T}||_{2}^{2}]$
\end{itemize}


\section{Training Paradigm}
\label{sec:model_training_paradigm}
    \subsection{Learning Objective and Loss Function(s)}
    \label{sec:model_loss_functions}
    % - The overall objective the model is trained to optimize.
    % - Specific loss components and their roles.
    % - e.g., For MTR: Gaussian Regression Loss (NLL) and auxiliary L1 regression loss. 
    % - Any specific strategies like hard assignment in MTR. 
    \subsection{Optimization Strategy and Training Details}
    \label{sec:model_optimization_details}
    % - Optimizer used, learning rate, batch size, epochs etc. 
    % - How iterative improvements are achieved during training (e.g. loss on intermediate decoder layers for MTR ).
    
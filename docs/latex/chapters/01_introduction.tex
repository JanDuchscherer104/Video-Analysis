\section{Introduction}
\label{sect:introduction}

\subsection{The Autonomous Driving Stack}
Safe and efficient navigation in autonomous driving hinges on a multi-stage pipeline of \emph{perception}, \emph{prediction}, \emph{ego-planning} and \emph{control}~\cite{hu2023planning}. The perception module processes raw sensor streams such as LiDAR, radar, and multi-view camera data to produce a rich representation of the scene, including the (kinematic) states of all traffic participants (\emph{agents}, i.e., vehicles, pedestrians, cyclists) and static map elements like lane markings, traffic lights and pedestrian crossings \cite{lmformerYadav2025}.
This vectorized scene-representation serves as the input to the \emph{motion forecasting} module, which is tasked with inferring the future trajectories of all agents in the scene over some planning horizon. The output is not a single, deterministic path, but a probabilistic, multimodal distribution over possible futures of each agent, which enables the pro-active planning of feasible and safe maneuvers and ego-trajectories from which the control module can derive the necessary vehicle commands.

\subsection{Challenges in Multi-Agent Motion Forecasting}
Despite impressive advances, three interrelated challenges limit current motion forecasting models
The behavior of traffic participants is inherently \emph{non-deterministic} and involves highly complex interactions with the environment and other agents. This necessitates models that can capture these complex dynamics and produce diverse, probabilistic motion forecasts to account for the wide range of possible future behaviors, whose uncertainty grows exponentially with the planning horizon as errors compound over time.
Attention-based architectures have emerged as powerful tools to model these complex interactions and overcome the issue of \emph{mode collapse} that plagued earlier approaches. However, traditional \emph{agent-centric} encoding schemes require expensive per-frame re-normalization, preventing the caching and reuse of previously computed features and hindering real-time performance\cite{qcnextZhou2023}.
Third, \emph{scalability and generalization} remain elusive: models trained on a single dataset like nuScenes, Argoverse 2, and Waymo~\cite{caesar2020nuscenes, av2Wilson2023, wmodSun2020} often fail to transfer across benchmarks with disparate formats, sampling rates, and map semantics~\cite{unitrajFeng2024}.

\subsection{Contributions and Report Structure}
 We begin in~\autoref{sec:background} by reviewing key forecasting paradigms and explore the query-centric encoding scheme~\cite{qcnetZhou2023} as a \emph{geometrically} elegant solution towards \emph{joint motion forecasting} and \emph{streaming inference} in autonomous driving in~\autoref{ssec:qc_paradigm}.\\
 We then introduce the \texttt{UniTraj} framework~\cite{unitrajFeng2024} in~\autoref{ch:unitraj}, which provides a unified interface for single-agent trajectory prediction across multiple datasets. Here, we describe the practical contributions of this seminar work.\\
In~\autoref{sec:data_methodology}, we introduce \texttt{UniTraj}'s data harmonization pipeline, which converts heterogeneous datasets into a single, agent-centric format.\\
Building on the insights established in~\autoref{sec:background},
we then provide in-depth reviews of four selected motion-forecasting models in~\autoref{ch:model_architecture}:
\autoref{ssec:caspnet} introduces a conceptually simple raster-based approach, the \texttt{CASPNet}~\cite{caspnetSch√§fer2022}. Following this, \autoref{ssec:caspformer} presents the \texttt{CASPFormer}, a hybrid CNN-transformer architecture that extends the raster-based approach to incorporate attention mechanisms for improved feature extraction and interaction modeling.
Next,~\autoref{ssec:mtr} discusses the \texttt{MTR}~\cite{Shi2022MTR}, another agent-centric model which was implemented within the \texttt{UniTraj} framework.
Finally, \autoref{ssec:lmformer} presents the LMFormer~\cite{lmformerYadav2025}, a query-centric model that maintains various invariances throughout the entire pipeline.\\
In~\autoref{ch:experimental_design_and_results} we describe the experimental design and results of training the \texttt{MTR} within the \texttt{UniTraj} framework and validate the results with those reported in the \texttt{UniTraj} paper~\cite{unitrajFeng2024}.

\newpage
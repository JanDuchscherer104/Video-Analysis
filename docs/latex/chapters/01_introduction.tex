\section{Introduction}
\label{sect:introduction}

\subsection{The Autonomous Driving Stack}
Safe and efficient navigation in autonomous driving hinges on a multi-stage pipeline of \emph{perception}, \emph{prediction}, \emph{ego-planning} and \emph{control} \cite{hu2023planning}. The perception module processes raw sensor streams such as LiDAR, radar, and multi-view camera data to produce a rich representation of the scene, including the (kinematic) states of all traffic participants (\emph{agents}, i.e., vehicles, pedestrians, cyclists) and static map elements like lane markings, traffic lights and pedestrian crossings \cite{lmformerYadav2025}.
This vectorized scene-representation serves as the input to the \emph{motion forecasting} module, which is tasked with inferring the future trajectories of all agents in the scene over some planning horizon. The output is not a single, deterministic path, but a probabilistic, multimodal distribution over possible futures of each agent, which enables the pro-active planning of feasible and safe maneuvers and ego-trajectories from which the control module can derive the necessary vehicle commands.

\subsection{Challenges in Multi-Agent Motion Forecasting}
Despite impressive advances, three interrelated challenges limit current motion forecasting models
The behavior of traffic participants is inherently \emph{non-deterministic} and involves highly complex interactions with the environment and other agents. This necessitates models that can capture these complex dynamics and produce diverse, probabilistic motion forecasts to account for the wide range of possible future behaviors, whose uncertainty grows exponentially with the planning horizon as errors compound over time.
Attention-based architectures have emerged as powerful tools to model these complex interactions and overcome the issue of \emph{mode collapse} that plagued earlier approaches. However, traditional \emph{agent-centric} encoding schemes require expensive per-frame re-normalization, preventing the caching and reuse of previously computed features and hindering real-time performance\cite{qcnextZhou2023}.
Third, \emph{scalability and generalization} remain elusive: models trained on a single dataset like nuScenes, Argoverse 2, and Waymo \cite{caesar2020nuscenes, av2Wilson2023, wmodSun2020} often fail to transfer across benchmarks with disparate formats, sampling rates, and map semantics \cite{unitrajFeng2024}.

\subsection{Contributions and Report Structure}
In this report, we explore these challenges by unifying data, theory, and models within the \texttt{UniTraj} framework.

We begin in Section~\ref{sec:background} by reviewing geometric deep learning foundations and key forecasting paradigms. In Section~\ref{ch:data}, we introduce \texttt{UniTraj}'s data harmonization pipeline, which converts heterogeneous datasets into a single, agent-centric format. Section~\ref{ch:qc} delivers a formal analysis of the query-centric encoding paradigm, highlighting its invariance properties and efficiency gains. Building on these insights, Section~\ref{ch:model} presents the Smol-LMFormer, a minimal, lane-aware transformer reimplementation of the model proposed in \cite{lmformerYadav2025}. Finally, Sections~\ref{ch:results} and \ref{ch:conclusion} validate our approach by comparing it against the MTR within the \texttt{UniTraj} framework.

\section{Related Work}\label{section:related_work}
The lane-aware trajectory prediction task primarily involves three important challenges: scene representation, learning a lane graph, and forcing the diversity in the outputs. We review some of the important related work for these strategies in this section.

\subsection{Scene Representation}\label{subsection:scene_rep}
Earlier works \cite{cui2019multimodal,chai2019multipath} rely on rasterized representations of the surrounding scene, where static and dynamic context information is stored across the channel dimension. These representations allow for the use of \acp{cnn} to extract meaningful features. However, rasterized representations suffer from limited resolution and include redundant pixel information, motivating the exploration of more compact scene representations. LaneGCN \cite{liang2020learning} first introduced the idea that HD maps inherently possess a graph structure, leveraging graph convolution to encode this information. Building on this, VectorNet \cite{gao2020vectornet} proposed a unified vector representation for various scene elements, including lanes, crosswalks, traffic lights, and surrounding agents. Despite these innovations, vector-based approaches face a limitation: they encode scene elements from the perspective of the target vehicle, necessitating re-normalization and re-encoding at each time step, which introduces redundant computations. QCNet \cite{zhou2023query} addresses this issue by adopting a query-centric approach. It encodes each scene element in its own coordinate frame, removing the need for re-normalization and re-encoding. Additionally, QCNet employs temporal and spatial embeddings to capture relative information across scene elements effectively. In our work, we adopt the query-centric vector-based approach to encode scene elements, as it offers lower computational complexity compared to agent-centric and rasterized representations.

\subsection{Lane Graph} \label{subsection:lane_graph}
The lane information in the static context for motion prediction tasks is typically stored as lane polylines. Each polyline is represented as $L_p^i = [P_1^i, P_2^i, ...., P_K^i]$, where $K$ denotes the number of control points in the polyline $i$, and $P_k^i$ denotes the position of these control points in the global coordinate system. Prior studies \cite{gao2020vectornet,ngiam2021scene,liu2024laformer} first transform the polylines into the target agent coordinate system before generating their corresponding encodings. On the other hand, the approaches \cite{liang2020learning,wang2022ltp,zhou2022hivt,zhou2023query} first convert the point-based representation of the polylines to segment-based representation; $L_v^i = [V_1^i, V_2^i, ...., V_{K-1}^i]$, where $V_{k}^i = [P_k^i, P_{k+1}^i]$ stores the vector information of lane segments. In this case, the lane features are generated from the vectors of individual segments. The advantage of the segment-based approach is that road curvature is explicitly encoded in the lane encodings. A potential limitation of all the aforementioned approaches is that they fail to use explicit information on lane connections at intersections, lane splits, and lane merges. 
Sun et al. \cite{sun2024semanticformer} attempt to use lane connection information to generate consistent lanes. However, their method requires an extensive map ontology, the creation and maintenance of which is expensive and thus has limited scalability. Therefore, in our work, we propose a simple mechanism to use the lane connection information together with the segment-based representation. This integrated approach not only achieves SOTA performance, but also improves the explainability of the prediction module.  

% LaneGCN \cite{liang2020learning} pioneered the idea that lanes are among the most important static context elements for motion prediction modules. However, its convolution-based architecture performs poorly in comparison to other transformer-based approaches \cite{ngiam2021scene,zhou2022hivt}. Wang et al. \cite{wang2022ltp} argue that lane segments within the static context are particularly suitable for behavioral intent modeling. However, the authors model this intent independently of the prediction task, using a three-layer MLP to score individual lane segments. Similarly, Liu et al. \cite{liu2024laformer} score the top-k potential lane segments through interaction graphs and subsequently decode trajectories using contextual information gathered from these selected segments. In parallel, Sun et al. \cite{sun2024semanticformer} propose generating Meta-Paths based solely on static context, representing paths that the target vehicle could traverse in the near future. These learned Meta-Paths are then utilized as anchors for predicting future trajectories. A common limitation of these aforementioned approaches is that the attention mechanisms used for extracting contextual information from road lanes operate independently of the prediction task. In contrast, our work incorporates lane awareness directly into the Transformer attention mechanism within the motion prediction module. This integrated approach not only achieves SOTA performance but also enhances the explainability of the prediction module.  

\subsection{Multi-Modal Prediction}\label{section:multi-modal-prediction}
To safely plan paths in complex traffic scenarios, motion prediction modules must generate multiple modes, each representing a scene-consistent trajectory. The advent of vector-based scene representations has enabled researchers to explore techniques such as \acp{VAE} \cite{casas2020implicit,cui2021lookout} and \acp{GAN} \cite{huang2020diversitygan} for producing diverse trajectory predictions. However, these approaches often suffer from mode collapse, where all predicted modes converge to a single trajectory with minor variations. In contrast, transformer architectures leveraging learnable anchors have achieved notable success in generating diverse trajectory predictions \cite{liu2021multimodal,ngiam2021scene,zhou2022hivt,zhou2023query}. Current SOTA methods build on transformer backbones and incorporate advanced techniques, including asked auto encoders \cite{cheng2023forecast,lan2023sept}, knowledge graphs \cite{sun2024semanticformer}, and language models \cite{seff2023motionlm}. These approaches have been extensively validated on open-source datasets such as nuScenes \cite{caesar2020nuscenes}, Argoverse \cite{chang2019argoverse}, Argoverse 2 \cite{wilson2023argoverse}, and Waymo \cite{mei2022waymo}. Building on this trend, UniTraj \cite{feng2024unitraj} introduces a unified framework that consolidates different datasets, network architectures, and evaluation criteria, enabling the development of larger and more generalized models.